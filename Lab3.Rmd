---
title: "Lab 3: Polygons and Rasters"
---

\
```{r}
library(sf)
library(MapGAM)
library(tidyverse)
library(tidycensus)
library(tigris)
library(flextable)
library(terra)
```

In [Lab 2](lab2.html), we worked with the tidycensus package and the Census API to bring in Census data into R. We can use the same commands to bring in Census geography. If you haven’t already, make sure to [sign up for and install your Census API key](https://api.census.gov/data/key_signup.html). If you could not install your API key, you’ll need to use `census_api_key()` to activate it.

```{r, eval = FALSE}
census_api_key("YOUR API KEY GOES HERE", install = TRUE)
```

```{r, echo=FALSE, eval=FALSE}
census_api_key("5d68935c96c26ee67ca52eb973d71e4a7b8490ad", install = TRUE)
```
\

Use the `set_acs()` command to bring in California tract-level race/ethnicity counts, total population, and total number of households. How did I find the variable IDs? Check [Lab 2](Lab2.html). Since we want tracts, we’ll use the `geography = "tract"` argument.
```{r}
ca.tracts <- get_acs(geography = "tract", 
              year = 2023,
              variables = c(tpopr = "B03002_001", 
                            nhwhite = "B03002_003", nhblk = "B03002_004", 
                            nhasn = "B03002_006", hisp = "B03002_012"), 
              state = "CA",
              output = "wide",
              survey = "acs5",
              geometry = TRUE,
              cb = FALSE)
```

\

The only difference between the code above and what we used in [Lab 2](lab2.html) is we have one additional argument added to the `get_acs()` command: `geometry = TRUE`. This tells R to bring in the spatial features associated with the geography you specified in the command, in the above case California tracts. You can set `cache_table = TRUE` so that you don’t have to re-download after you’ve downloaded successfully the first time. This is important because you might be downloading a really large file, or may encounter Census FTP issues when trying to collect data. 

\

We can also download the data another way. We can go to the [Census Shapefiles website](https://www.census.gov/cgi-bin/geo/shapefiles/index.php) and navigate to 2023, Census Tracts, then California. We will then download a .zip file that contains an ESRI shapefile of the Census tracts for California. When we unzip the file, we see a series of files. Thankfully, the **sf** package has an `st_read()` function that can tackle this! For more detailed data downloads, you can use [National Historical Geographic Information System (NHGIS)](https://www.nhgis.org/).

```{r eval=FALSE}
ca.tracts <- st_read("/Users/pjames1/Downloads/tl_2024_06_tract/tl_2024_06_tract.shp")
```


Lets take a look at our data.

\

```{r}
ca.tracts
```

\

The object looks much like a basic tibble, but with a few differences.

  - You’ll find that the description of the object now indicates that it is a simple feature collection with 9,129 features (tracts in   - California) with 13 fields (attributes or columns of data).
  - The `Geometry Type` indicates that the spatial data are in `MULTIPOLYGON` form (as opposed to points or lines, the other basic vector data forms).
  - `Bounding box` indicates the spatial extent of the features (from left to right, for example, California tracts go from a longitude of -124.482 to -114.1312).
  - `Geodetic CRS` tells us the coordinate reference system.
  - The final difference is that the data frame contains the column geometry. This column (a list-column) contains the geometry for each observation. This looks familiar!
  
At its most basic, an **sf** object is a collection of simple features that includes attributes and geometries in the form of a data frame. In other words, it is a data frame (or tibble) with rows of features, columns of attributes, and a special column always named geometry that contains the spatial aspects of the features.

If you want to peek behind the curtain and learn more about the nitty gritty details about simple features, check out the official **sf** [vignette.](https://r-spatial.github.io/sf/articles/sf1.html)

\

# Data Wrangling

There is a lot of stuff [behind the curtain](https://www.jessesadler.com/post/simple-feature-objects/) of how R handles spatial data as simple features, but the main takeaway is that **sf** objects are data frames. This means you can use many of the **tidyverse** functions we’ve learned in the past couple labs to manipulate **sf** objects, including the pipe `%>%` operator. For example, let’s do the following data wrangling tasks on `ca.tracts`.

1. Keep necessary variables using the `select()` function
2. Break up the column *NAME* into separate tract, county and state variables using the `separate()` function

We do all of this in one line of continuous code using the pipe operator `%>%`

```{r}
ca.tracts <- ca.tracts %>%
              dplyr::select(GEOID, NAME, tpoprE, nhwhiteE, nhblkE, nhasnE, hispE) %>%
              separate(NAME, c("Tract", "County", "State"), sep = "; ")

glimpse(ca.tracts)
```

\

Another important data wrangling operation is to join attribute data to an sf object. For example, let’s say you wanted to add tract level median household income, which is located in the file ca_med_inc_2018.csv. Read the file in.

```{r}
ca.inc <- get_acs(geography = "tract", 
              year = 2023,
              variables = c(medinc = "B19013_001"), 
              state = "CA",
              survey = "acs5",
              output = "wide")
```

\

Unlike before, we brought these data in without the `geometry = TRUE` option. So this is just a table. But remember, an **sf** object is a data frame, so we can use `left_join()`, which we covered in [Lab 1](lab1.html), to join the files *ca.inc* and *ca.tracts*.

```{r}
ca.tracts <- ca.tracts %>%
  left_join(ca.inc, by = "GEOID")

#take a look to make sure the join worked
glimpse(ca.tracts)
```

\

Note that we can’t use `left_join()` to join the attribute tables of two **sf** files. You will need to either make one of them not spatial by using the `st_drop_geometry()` function or use the `st_join()` function to spatially join them.

We use the function `tm_shape()` from the **tmap** package to map the data. 

```{r}
tmap_mode("plot")
tract_map <- tm_shape(ca.tracts) +   tm_polygons()
tract_map
```

\

# Spatial Data Wrangling

There is Data Wrangling and then there is Spatial Data Wrangling. Cue dangerous sounding music. Well, it’s not that dangerous or scary. Spatial Data Wrangling involves cleaning or altering your data set based on the geographic location of features. The **sf** package offers a suite of functions unique to wrangling spatial data. Most of these functions start out with the prefix `st_`. To see all of the functions, type in

```{r}
methods(class = "sf")
```

\

We won’t go through all of these functions as the list is quite extensive. But, we’ll go through a few relevant spatial operations for this class below. The function we will be primarily using is `st_join()`.

## Intersect

A common spatial data wrangling issue is to subset a set of spatial objects based on their location relative to another spatial object. In our case, we want to keep California tracts that are in the Sacramento metro area. We can do this using the `st_join()` function. We’ll need to specify a type of join. Let’s first try `join = st_intersects`. First, let's bring in a polygon of the Sacramento metro area from Github.

```{r}
url <- "https://github.com/pjames-ucdavis/SPH215/raw/main/sac.metro.rds"
download.file(url, destfile = "sac.metro.rds", mode = "wb")
sac.metro <- readRDS("sac.metro.rds")
```

\

Let's take a look at *sac.metro* and understand what file it is.

```{r}
glimpse(sac.metro)
```

\

OK, that geometry looks good. And it's a polygon, so that's good. Let's now try to intersect our *sac.metro* dataset with our *ca.tracts* dataset. 

```{r}
sac.metro.tracts.int <- st_join(ca.tracts, sac.metro, 
                                join = st_intersects, left=FALSE)
```

\

The above code tells R to identify the polygons in *ca.tracts* that intersect with the polygon *sac.metro*. We indicate we want a polygon intersection by specifying `join = st_intersects`. The option `left=FALSE` tells R to remove the polygons from *ca.tracts* that do not intersect (make it TRUE and see what happens) with *sac.metro*. Plotting our tracts, we get:
```{r}
tm_shape(sac.metro.tracts.int) +
  tm_polygons(col = "blue") +
tm_shape(sac.metro) +  
  tm_borders(col = "red")
```

\

## Within

We have one small issue. Using `join = st_intersects` returns all tracts that intersect *sac.metro*, which include those that touch the metro’s boundary. No bueno. We can instead use the argument `join = st_within` to return tracts that are *completely within* the metro area.

```{r}
sac.metro.tracts.w <- st_join(ca.tracts, sac.metro, join = st_within, left=FALSE)

tm_shape(sac.metro.tracts.w) +
  tm_polygons(col = "blue") +
tm_shape(sac.metro) +
  tm_borders(col = "red")
```

\

Looking much better! Now, if we look at *sac.metro.tracts.w*’s attribute table, you’ll see it includes all the variables from both *ca.tracts* and *sac.metro*. We don’t need these variables, so use `select()` to eliminate them. You’ll also notice that if variables from two data sets share the same name, R will keep both and attach a *.x* and *.y* to the end. For example, I was found in both *ca.tracts* and *sac.metro*, so R named one *GEOID.x* and the other that was merged in was named *GEOID.y*.

\

# Mapping in R

OK, so now we've talked a little about how to bring in and manipulate vector polygon data, let's do some mapping and create some choropleth maps. We can do this with the **ggplot** package, the **tmap** package, and the **leaflet** package (which we won't cover now, but it's very cool for interactive maps). Let's start with **ggplot**.

## Choropleth maps in ggplot

Because **sf** is tidy friendly, it is no surprise we can use the **tidyverse** plotting function `ggplot()` to make maps. We already received an introduction to `ggplot()` in [Lab 2](lab2.html). Recall its basic structure:

```{r, eval=FALSE}
ggplot(data = <DATA>) +
      <GEOM_FUNCTION>(mapping = aes(x, y)) +
      <OPTIONS>()
```

\

In mapping, `geom_sf()` is `<GEOM_FUNCTION>()`. Unlike with functions like `geom_histogram()` and `geom_boxplot()`, we don’t specify an x and y axis. Instead you use `fill` if you want to map a variable or color to just map boundaries.

Let’s use `ggplot()` to make a choropleth map. We need to specify a numeric variable in the `fill =` argument within `geom_sf()`. Here we map tract-level median household income in the Sacramento metro area.

```{r}
ggplot(data = sac.metro.tracts.w) +
  geom_sf(aes(fill = medincE))
```

\

We can also specify a title (as well as subtitles and captions) using the `labs()` function.


```{r}
ggplot(data = sac.metro.tracts.w) +
  geom_sf(aes(fill = medincE)) +
    labs(title = "Median Income Sacramento MSA Tracts") 
```

\

We can make further layout adjustments to the map. Don’t like a blue scale on the legend? You can change it using the `scale_file_gradient()` function. Let’s change it to a white to red gradient. We can also eliminate the gray tract border colors to make the fill color distinction clearer. We do this by specifying `color = NA` inside `geom_sf()`. We can also get rid of the gray background by specifying a basic black and white theme using `theme_bw()`. We also added a caption indicating the source of the data using the `captions =` parameter within `labs()`. We then changed the color to red using labels for `low=` and `high=`, and we added a name to our legend with `name='.

```{r}
ggplot(data = sac.metro.tracts.w) +
  geom_sf(aes(fill = medincE), color = NA) +
    scale_fill_gradient(low= "white", high = "red", na.value ="gray", name = "Median Income") +  
    labs(title = "Median Income Sacramento MSA Tracts",
         caption = "Source: American Community Survey") +  
  theme_bw()
```
Dare I say, we are ready for the New York Times with this map!

\

## Points on top of polygons

OK, now that we have mapped points and mapped polygons, let's put them both together!


# FINALIZE

## tmap

Whether you prefer **tmap** or **ggplot** is up to you, but I find that **tmap** has some benefits, so let’s focus on its mapping functions next.

**tmap** uses the same layered logic as **ggplot**. As we saw last week, the initial command is `tm_shape()`, which specifies the geography to which the mapping is applied. You then build on `tm_shape()` by adding one or more elements such as `tm_polygons()` for polygons, `tm_borders()` for lines, and `tm_dots()` for points. All additional functions take on the form of `tm_`. Check the full list of `tm_` elements [here](https://www.rdocumentation.org/packages/tmap/versions/2.0/topics/tmap-element).

### Choropleth maps in tmap

Let’s make a static choropleth map of median household income in Sacramento MSA just like we did above, but this time in **tmap**.

```{r}
tm_shape(sac.metro.tracts.w) +
  tm_polygons(col = "medincE", style = "quantile")
```

\

We first put the dataset *sac.metro.tracts.w* inside `tm_shape()`. Because you are plotting polygons, you use `tm_polygons()` next. The argument `col = "medincE"` tells R to shade (or color) the tracts by the variable *medincE.* The argument `style = "quantile"` tells R to break up the shading into quantiles, or equal groups of 5 as a default. I find that this is where **tmap** offers a distinct advantage over **ggplot** in that users have greater control over the legend and bin breaks. **tmap** allows users to specify algorithms to automatically create breaks with the style argument. You can also change the number of breaks by setting `n=`. The default is `n=5`. Rather than quintiles, you can show quartiles using `n=4`. I'm feeling crazy. Let's do it.

```{r}
tm_shape(sac.metro.tracts.w) +
  tm_polygons(col = "medincE", style = "quantile",  n=4)
```

\

Check out [this link](https://geocompr.robinlovelace.net/adv-map.html#color-settings) for more on  available classification styles in **tmap**.

You can overlay multiple features on one map. For example, we can add park polygons on top of tracts, providing a visual association between parks and percent white. You will need to add two `tm_shape()` functions each for *sac.metro.tracts.w* and *parks*.

### Color scheme
### Legend
### Title
### Scale bar and arrow
### Dot map
### Interactive Maps
## leaflet
## Saving maps



# Rasters

Raster datasets are simply an array of pixels/cells organized into rows and columns (or a grid) where each cell contains a value representing information, such as temperature, soil type, land use, water level. Raster maps usually represent continuous phenomena such as elevation, temperature, population density or spectral data. Discrete features such as soil or land-cover classes can also be represented in the raster data model. Rasters are aerial photographs, imagery from satellites, google street view images. Few things to note.

 - Raster datasets are always rectangular (rows x col) similar to matrices. Irregular boundaries are created by using NAs.
 - Rasters have to contain values of the same type (int, float, boolean) throughout the raster, just like matrices and unlike data frames.
 - The size of the raster depends on the resolution and the extent of the raster. As such many rasters are large and often cannot be held in memory completely.
 - The workhorse package for working with rasters in R is raster and terra packages by Robert Hijmans. terra is better and faster in many instances, but is newer and does not have all the functionality and support associated with raster.

Typically you will bring in a raster dataset directly from a file. These files come in many different forms, typically .tif, .img, and .grd.

We’ll bring in the files sac_county_lc.tif and nlcd_classes.csv. The first file contains USGS land cover (for example, Low Intensity Developed, Deciduous Forest) for Sacramento county based on classes defined by the National Land Cover Dataset. The second file contains the descriptions of the land cover classes.

We use the function raster() to bring in data into raster form.
